{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerekli kütüphanelerin import edilmesi\n",
    "import warnings\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, Bidirectional, GRU\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "py.init_notebook_mode(connected=True)\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datanın Yüklenmesi\n",
    "data = pd.read_excel('dataset.xlsx', date_parser=[0])\n",
    "\n",
    "# İlk 5 Satır\n",
    "print(data.head())\n",
    "#Son 5 satır\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datetime Haline Getirilmesi\n",
    "data['tarih'] = pd.to_datetime(data.tarih, format='%d-%m-%Y')\n",
    "\n",
    "#İndex'e Alınması\n",
    "data.index = data.tarih\n",
    "\n",
    "#Bilindiği gibi cumartesi pazar piyasalar kapalı ve burada da o yüzden o datalar NaN gözüküyor. \n",
    "#Bunların doldurulması için interpolate fonksiyonunu kullanabiliriz. \n",
    "#Bu fonksiyon haftaya bakarak lineer olarak dolduruyor.\n",
    "data['usd_alis'].interpolate(method='linear', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doların 2000 Ekim-2019 Mart arasındaki değişimi\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "data.usd_alis.plot(label='usd alış')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Günlük Döviz Alış Kurları', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verinin derin öğrenme modellerine ve LSTM’e verilmeden önce 0-1 arasınaa scale edilmesi.\n",
    "#Bu scale işlemi yapılmadan da model çalışabilir fakat scale edilme işlemi sonrası elde edilen sonuçlar ciddi oranda\n",
    "#daha başarılı\n",
    "values = data['usd_alis'].values.reshape(-1,1)\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(values)\n",
    "\n",
    "# Birkaç Değere Bakalım\n",
    "dataset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veri setinin eğitim ve test diye 2 ye bölünmesi. %80 Eğitim % 20 Test\n",
    "TRAIN_SIZE = 0.80\n",
    "\n",
    "train_size = int(len(dataset) * TRAIN_SIZE)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Gün Sayıları (eğitim seti, test seti): \" + str((len(train), len(test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veri setinin adım adım okunması için ön işleme adımları \n",
    "#Buradaki mantık son güne bakıp diğer günün tahmin edilmesi şeklinde olacak.\n",
    "#window_size=1  1 gün önceye bakma şeklinde. Başka denemeler için parametrik\n",
    "def create_dataset(dataset, window_size = 1):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - window_size - 1):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + window_size, 0])\n",
    "    return(np.array(data_X), np.array(data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verisetlerimizi Oluşturalım\n",
    "window_size = 1\n",
    "train_X, train_Y = create_dataset(train, window_size)\n",
    "test_X, test_Y = create_dataset(test, window_size)\n",
    "print(\"Orijinal eğitim veri seti şekli:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "# Yeni verisetinin şekline bakalım.\n",
    "#The LSTM giriş katmanı 3D olmak zorunda.Bu 3 boyut: örnek sayısı, zaman aralığı ve özellikler.\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(\"Yeni eğitim veri seti şekli:\")\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Şimdi ise LSTM Modelimizi kuralım.\n",
    "def fit_model(train_X, train_Y, window_size = 1):\n",
    "    #Bir girdi tensoru ve bir çıktı tensoru olduğu durumlarda en uygun seçim sequential\n",
    "    model = Sequential() \n",
    "    # Model tek layerlı şekilde kurulacak.\n",
    "    model.add(LSTM(100, input_shape = (1, window_size)))\n",
    "    model.add(Dense(1)) #1 nöron içeren gizli katman\n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = \"adam\") #kullanılacak hata fonksiyonu ve optimizer(stochastic gradient descent metodu)\n",
    "   #30 epoch yani 30 kere veri setine bakılacak.\n",
    "    model.fit(train_X, \n",
    "              train_Y, \n",
    "              epochs = 30, \n",
    "              batch_size = 1, \n",
    "              verbose = 1)\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "# Modelin eğitim veri seti ile eğitilmesi\n",
    "model1 = fit_model(train_X, train_Y, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sonuçların ölçülmesi\n",
    "def predict_and_score(model, X, Y):\n",
    "    # Tahminlerin 0-1 ile scale edilmiş halinden geri çevrilmesi.\n",
    "    pred = scaler.inverse_transform(model.predict(X))\n",
    "    orig_data = scaler.inverse_transform([Y])\n",
    "    # Rmse(hata) değerlerinin ölçülmesi\n",
    "    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n",
    "    return(score, pred)\n",
    "\n",
    "rmse_train, train_predict = predict_and_score(model1, train_X, train_Y)\n",
    "rmse_test, test_predict = predict_and_score(model1, test_X, test_Y)\n",
    "\n",
    "print(\"Eğitim veri seti skoru: %.2f RMSE\" % rmse_train)\n",
    "print(\"Test veri seti skoru: %.2f RMSE\" % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elde edilen sonuçların görselleştirilmesi\n",
    "# Öğrendiklerinin tahminletilmesi\n",
    "train_predict_plot = np.empty_like(dataset)\n",
    "train_predict_plot[:, :] = np.nan\n",
    "train_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict\n",
    "\n",
    "# Testlerin tahminletilmesi\n",
    "test_predict_plot = np.empty_like(dataset)\n",
    "test_predict_plot[:, :] = np.nan\n",
    "test_predict_plot[len(train_predict) + (window_size * 2) + 1:len(dataset) - 1, :] = test_predict\n",
    "\n",
    "# Grafik haline getirilmesi\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(scaler.inverse_transform(dataset), label = \"Gerçek Değer\")\n",
    "plt.plot(train_predict_plot, label = \"Eğitim Veri Seti Tahmini\")\n",
    "plt.plot(test_predict_plot, label = \"Test Veri Seti Tahmini\")\n",
    "plt.xlabel(\"Günler\")\n",
    "plt.ylabel(\"Döviz Kurları\")\n",
    "plt.title(\"Gerçek ve Tahmin Edilen Eğitim / Test Verileri Karşılaştırılması\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
